# S3 åŒæ­¥æ–¹æ¡ˆæŠ€æœ¯è®¾è®¡

## 1. æ–¹æ¡ˆæ¦‚è¿°

ä½¿ç”¨ AWS S3ï¼ˆæˆ–å…¼å®¹æœåŠ¡ï¼‰ä½œä¸ºä¸­å¿ƒåŒ–å­˜å‚¨ï¼Œå®ç°å¤šè®¾å¤‡æ•°æ®åŒæ­¥ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

- âœ… **æˆæœ¬ä½**ï¼š$0-5/æœˆï¼ˆæ¨è Cloudflare R2 é›¶æˆæœ¬ï¼‰
- âœ… **é«˜å¯é **ï¼š99.999999999% æ•°æ®æŒä¹…æ€§
- âœ… **ç®€å•**ï¼šæ— éœ€ç»´æŠ¤æœåŠ¡å™¨
- âœ… **è·¨å¹³å°**ï¼šæ‰€æœ‰è®¾å¤‡éƒ½æ”¯æŒ
- âœ… **å…¨çƒ CDN**ï¼šè®¿é—®é€Ÿåº¦å¿«

### æ”¯æŒçš„ S3 å…¼å®¹æœåŠ¡

| æœåŠ¡å•† | æœˆè´¹ç”¨ | å…è´¹é¢åº¦ | æ¨èåº¦ |
|--------|--------|----------|--------|
| **Cloudflare R2** | $0.015/GB | 10GBå…è´¹ + é›¶å‡ºç«™è´¹ç”¨ | â­â­â­â­â­ |
| **AWS S3** | $0.023/GB | 12ä¸ªæœˆå…è´¹ | â­â­â­â­ |
| **MinIO** | è‡ªæ‰˜ç®¡/$0 | æ— é™ | â­â­â­â­ |
| **Backblaze B2** | $0.005/GB | 10GBå…è´¹ | â­â­â­â­ |
| **é˜¿é‡Œäº‘ OSS** | Â¥0.12/GB | 3ä¸ªæœˆå…è´¹ | â­â­â­â­ |

**æ¨èï¼šCloudflare R2**ï¼ˆé›¶å‡ºç«™è´¹ç”¨ï¼Œæ€§ä»·æ¯”æœ€é«˜ï¼‰

---

## 2. æ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "è®¾å¤‡ A (Mac)"
        A1[Tauri App A]
        A2[Local SQLite]
        A3[CRDT Engine]
    end
    
    subgraph "è®¾å¤‡ B (Mac)"
        B1[Tauri App B]
        B2[Local SQLite]
        B3[CRDT Engine]
    end
    
    subgraph "S3 å­˜å‚¨æ¡¶"
        S3_STATE["devices/<br/>è®¾å¤‡çŠ¶æ€"]
        S3_DELTAS["deltas/<br/>å¢é‡å˜æ›´"]
        S3_SNAPSHOTS["snapshots/<br/>å®Œæ•´å¿«ç…§"]
    end
    
    A1 -->|è¯»å†™| A2
    A2 -->|ç”Ÿæˆå˜æ›´| A3
    A3 -->|ä¸Šä¼ | S3_DELTAS
    A3 -->|å®šæœŸå¿«ç…§| S3_SNAPSHOTS
    A3 -->|æ³¨å†Œ| S3_STATE
    
    B3 -->|ä¸‹è½½| S3_DELTAS
    B3 -->|æ‹‰å–å¿«ç…§| S3_SNAPSHOTS
    B3 -->|è¯»çŠ¶æ€| S3_STATE
    B3 -->|åº”ç”¨å˜æ›´| B2
    B2 -->|è¯»å†™| B1
```

### 2.2 S3 ç›®å½•ç»“æ„

```
s3://my-project-sync/
â”œâ”€â”€ devices/                    # è®¾å¤‡æ³¨å†Œä¿¡æ¯
â”‚   â”œâ”€â”€ device-001.json        # è®¾å¤‡001ä¿¡æ¯
â”‚   â””â”€â”€ device-002.json        # è®¾å¤‡002ä¿¡æ¯
â”‚
â”œâ”€â”€ deltas/                     # å¢é‡å˜æ›´æ—¥å¿—
â”‚   â”œâ”€â”€ 2026/02/10/
â”‚   â”‚   â”œâ”€â”€ 001-device-001.json    # å˜æ›´åºå·-è®¾å¤‡ID
â”‚   â”‚   â”œâ”€â”€ 002-device-002.json
â”‚   â”‚   â””â”€â”€ 003-device-001.json
â”‚   â””â”€â”€ index.json             # å˜æ›´ç´¢å¼•ï¼ˆç‰ˆæœ¬å·ï¼‰
â”‚
â”œâ”€â”€ snapshots/                  # å®Œæ•´æ•°æ®å¿«ç…§
â”‚   â”œâ”€â”€ snapshot-v1000.json.gz # ç‰ˆæœ¬1000å¿«ç…§ï¼ˆå‹ç¼©ï¼‰
â”‚   â”œâ”€â”€ snapshot-v2000.json.gz
â”‚   â””â”€â”€ latest.json            # æœ€æ–°å¿«ç…§æŒ‡é’ˆ
â”‚
â””â”€â”€ metadata/                   # å…ƒæ•°æ®
    â”œâ”€â”€ schema-version.json    # æ•°æ®Schemaç‰ˆæœ¬
    â””â”€â”€ sync-config.json       # åŒæ­¥é…ç½®
```

### 2.3 æ•°æ®æµç¨‹

```
1. æœ¬åœ°å˜æ›´ â†’ ç”Ÿæˆ Delta â†’ ä¸Šä¼ åˆ° S3
2. å®šæ—¶æ‹‰å– â†’ ä¸‹è½½ Delta â†’ æ£€æµ‹å†²çª â†’ åº”ç”¨å˜æ›´
3. å®šæœŸå¿«ç…§ â†’ å‹ç¼©æ•°æ® â†’ ä¸Šä¼ å®Œæ•´å¤‡ä»½
```

### 2.4 åŒæ­¥è¦†ç›–çš„æ•°æ®è¡¨

ä»¥ä¸‹è¡¨çš„ INSERT/UPDATE/DELETE æ“ä½œé€šè¿‡ SQLite è§¦å‘å™¨è‡ªåŠ¨è®°å½•åˆ° `sync_metadata`ï¼Œçº³å…¥ Delta åŒæ­¥ï¼š

| è¡¨å | è§¦å‘å™¨å®šä¹‰ä½ç½® | è¯´æ˜ |
|------|---------------|------|
| `projects` | `0003_add_sync_support.sql` | é¡¹ç›®åŸºç¡€æ•°æ® |
| `persons` | `0003_add_sync_support.sql` | æˆå‘˜æ•°æ® |
| `partners` | `0003_add_sync_support.sql` | åˆä½œæ–¹æ•°æ® |
| `assignments` | `0003_add_sync_support.sql` | æˆå‘˜å‚ä¸è®°å½• |
| `status_history` | `0003_add_sync_support.sql` | çŠ¶æ€å˜æ›´å†å² |
| `project_tags` | `0003_add_sync_support.sql` | é¡¹ç›®æ ‡ç­¾ |
| `project_comments` | `0004_add_project_comments.sql` | é¡¹ç›®è¯„è®ºï¼ˆå¯Œæ–‡æœ¬ï¼‰|

---

## 3. æ ¸å¿ƒå®ç°

### 3.1 ä¾èµ–é…ç½®

```toml
# src-tauri/Cargo.toml

[dependencies]
aws-sdk-s3 = "1.60"
aws-config = "1.5"
tokio = { version = "1", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
chrono = "0.4"
uuid = { version = "1.11", features = ["v4"] }
sha2 = "0.10"
flate2 = "1.0"  # ç”¨äºå‹ç¼©
```

### 3.2 S3 å®¢æˆ·ç«¯å°è£…

```rust
// src-tauri/src/sync/s3_client.rs

use aws_config::meta::region::RegionProviderChain;
use aws_sdk_s3::{Client, Error as S3Error};
use serde::{Deserialize, Serialize};

pub struct S3SyncClient {
    client: Client,
    bucket: String,
    device_id: String,
}

impl S3SyncClient {
    /// åˆ›å»ºæ ‡å‡† S3 å®¢æˆ·ç«¯ï¼ˆAWSï¼‰
    pub async fn new(bucket: String, device_id: String) -> Result<Self, Box<dyn std::error::Error>> {
        let region_provider = RegionProviderChain::default_provider().or_else("us-east-1");
        let config = aws_config::from_env().region(region_provider).load().await;
        let client = Client::new(&config);
        
        Ok(Self {
            client,
            bucket,
            device_id,
        })
    }
    
    /// åˆ›å»ºè‡ªå®šä¹‰ç«¯ç‚¹å®¢æˆ·ç«¯ï¼ˆMinIO/R2/OSSç­‰ï¼‰
    pub async fn new_with_endpoint(
        bucket: String,
        device_id: String,
        endpoint: String,
        access_key: String,
        secret_key: String,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        use aws_credential_types::Credentials;
        
        let creds = Credentials::new(access_key, secret_key, None, None, "custom");
        
        let config = aws_config::from_env()
            .endpoint_url(endpoint)
            .credentials_provider(creds)
            .load()
            .await;
        
        let client = Client::new(&config);
        
        Ok(Self {
            client,
            bucket,
            device_id,
        })
    }
    
    /// ä¸Šä¼ å¯¹è±¡
    pub async fn upload(&self, key: &str, data: Vec<u8>) -> Result<(), S3Error> {
        let start = std::time::Instant::now();
        
        let result = self.client
            .put_object()
            .bucket(&self.bucket)
            .key(key)
            .body(data.into())
            .send()
            .await;
        
        let elapsed = start.elapsed();
        
        match &result {
            Ok(_) => log::info!("S3 upload: {} ({:.2?})", key, elapsed),
            Err(e) => log::error!("S3 upload failed: {} - {:?}", key, e),
        }
        
        result?;
        Ok(())
    }
    
    /// ä¸‹è½½å¯¹è±¡
    pub async fn download(&self, key: &str) -> Result<Vec<u8>, S3Error> {
        let resp = self.client
            .get_object()
            .bucket(&self.bucket)
            .key(key)
            .send()
            .await?;
        
        let data = resp.body.collect().await?.into_bytes().to_vec();
        Ok(data)
    }
    
    /// åˆ—å‡ºå¯¹è±¡ï¼ˆå¸¦å‰ç¼€è¿‡æ»¤ï¼‰
    pub async fn list(&self, prefix: &str) -> Result<Vec<String>, S3Error> {
        let resp = self.client
            .list_objects_v2()
            .bucket(&self.bucket)
            .prefix(prefix)
            .send()
            .await?;
        
        let keys = resp
            .contents()
            .iter()
            .filter_map(|obj| obj.key().map(String::from))
            .collect();
        
        Ok(keys)
    }
    
    /// åˆ é™¤å¯¹è±¡
    pub async fn delete(&self, key: &str) -> Result<(), S3Error> {
        self.client
            .delete_object()
            .bucket(&self.bucket)
            .key(key)
            .send()
            .await?;
        
        Ok(())
    }
    
    /// æ£€æŸ¥å¯¹è±¡æ˜¯å¦å­˜åœ¨
    pub async fn exists(&self, key: &str) -> Result<bool, S3Error> {
        match self.client
            .head_object()
            .bucket(&self.bucket)
            .key(key)
            .send()
            .await
        {
            Ok(_) => Ok(true),
            Err(_) => Ok(false),
        }
    }
}
```

### 3.3 å¢é‡åŒæ­¥å¼•æ“

```rust
// src-tauri/src/sync/delta_sync.rs

use chrono::Utc;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Delta {
    pub id: String,
    pub device_id: String,
    pub version: i64,
    pub timestamp: String,
    pub operations: Vec<Operation>,
    pub checksum: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Operation {
    pub table: String,
    pub record_id: String,
    pub op_type: OperationType,
    pub data: serde_json::Value,
    pub vector_clock: VectorClock,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum OperationType {
    Insert,
    Update,
    Delete,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VectorClock {
    pub clocks: HashMap<String, i64>,
}

impl VectorClock {
    pub fn new(device_id: String) -> Self {
        let mut clocks = HashMap::new();
        clocks.insert(device_id, 0);
        Self { clocks }
    }
    
    pub fn increment(&mut self, device_id: &str) {
        *self.clocks.entry(device_id.to_string()).or_insert(0) += 1;
    }
    
    pub fn merge(&mut self, other: &VectorClock) {
        for (device, clock) in &other.clocks {
            let entry = self.clocks.entry(device.clone()).or_insert(0);
            *entry = (*entry).max(*clock);
        }
    }
    
    /// åˆ¤æ–­æ˜¯å¦å­˜åœ¨å†²çª
    pub fn conflicts_with(&self, other: &VectorClock) -> bool {
        let mut self_greater = false;
        let mut other_greater = false;
        
        let all_devices: std::collections::HashSet<_> = self
            .clocks
            .keys()
            .chain(other.clocks.keys())
            .collect();
        
        for device in all_devices {
            let self_clock = self.clocks.get(device).unwrap_or(&0);
            let other_clock = other.clocks.get(device).unwrap_or(&0);
            
            if self_clock > other_clock {
                self_greater = true;
            } else if other_clock > self_clock {
                other_greater = true;
            }
        }
        
        self_greater && other_greater
    }
}

pub struct DeltaSyncEngine {
    s3_client: crate::sync::s3_client::S3SyncClient,
    local_version: i64,
    vector_clock: VectorClock,
}

impl DeltaSyncEngine {
    pub fn new(s3_client: crate::sync::s3_client::S3SyncClient, device_id: String) -> Self {
        Self {
            s3_client,
            local_version: 0,
            vector_clock: VectorClock::new(device_id),
        }
    }
    
    /// æ¨é€æœ¬åœ°å˜æ›´åˆ° S3
    pub async fn push(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        // 1. è·å–æœ¬åœ°æœªåŒæ­¥çš„å˜æ›´
        let operations = self.get_local_changes().await?;
        
        if operations.is_empty() {
            return Ok(());
        }
        
        // 2. é€’å¢ç‰ˆæœ¬å’Œå‘é‡æ—¶é’Ÿ
        self.local_version += 1;
        self.vector_clock.increment(&self.s3_client.device_id);
        
        // 3. åˆ›å»º Delta
        let delta = Delta {
            id: uuid::Uuid::new_v4().to_string(),
            device_id: self.s3_client.device_id.clone(),
            version: self.local_version,
            timestamp: Utc::now().to_rfc3339(),
            operations: operations.clone(),
            checksum: self.calculate_checksum(&operations),
        };
        
        // 4. ä¸Šä¼ åˆ° S3
        let key = format!(
            "deltas/{}/{:03}-{}.json",
            Utc::now().format("%Y/%m/%d"),
            delta.version,
            delta.device_id
        );
        
        let data = serde_json::to_vec(&delta)?;
        self.s3_client.upload(&key, data).await?;
        
        // 5. æ›´æ–°ç´¢å¼•
        self.update_index(&delta).await?;
        
        // 6. æ ‡è®°æœ¬åœ°å·²åŒæ­¥
        self.mark_synced(&operations).await?;
        
        log::info!("Pushed {} operations, version: {}", operations.len(), self.local_version);
        
        Ok(())
    }
    
    /// ä» S3 æ‹‰å–è¿œç¨‹å˜æ›´
    pub async fn pull(&mut self) -> Result<Vec<Delta>, Box<dyn std::error::Error>> {
        // 1. ä¸‹è½½ç´¢å¼•æ–‡ä»¶
        let index = self.download_index().await?;
        
        // 2. æ‰¾å‡ºæ–°çš„ deltasï¼ˆç‰ˆæœ¬å·å¤§äºæœ¬åœ°ï¼Œä¸”éè‡ªå·±åˆ›å»ºï¼‰
        let new_deltas: Vec<_> = index
            .into_iter()
            .filter(|d| d.version > self.local_version)
            .filter(|d| d.device_id != self.s3_client.device_id)
            .collect();
        
        if new_deltas.is_empty() {
            return Ok(vec![]);
        }
        
        // 3. ä¸‹è½½å¹¶åº”ç”¨ deltas
        let mut applied = Vec::new();
        
        for delta_meta in new_deltas {
            let key = format!(
                "deltas/{}/{:03}-{}.json",
                delta_meta.date,
                delta_meta.version,
                delta_meta.device_id
            );
            
            let data = self.s3_client.download(&key).await?;
            let delta: Delta = serde_json::from_slice(&data)?;
            
            // éªŒè¯æ ¡éªŒå’Œ
            if delta.checksum != self.calculate_checksum(&delta.operations) {
                log::error!("Checksum mismatch for delta {}", delta.id);
                continue;
            }
            
            // åº”ç”¨å˜æ›´
            self.apply_delta(&delta).await?;
            applied.push(delta);
        }
        
        log::info!("Pulled and applied {} deltas", applied.len());
        
        Ok(applied)
    }
    
    /// åº”ç”¨ Delta åˆ°æœ¬åœ°æ•°æ®åº“
    async fn apply_delta(&mut self, delta: &Delta) -> Result<(), Box<dyn std::error::Error>> {
        let conn = self.get_connection();
        let tx = conn.transaction()?;
        
        for op in &delta.operations {
            // æ£€æŸ¥å†²çª
            if let Some(local_clock) = self.get_local_vector_clock(&op.table, &op.record_id).await? {
                if local_clock.conflicts_with(&op.vector_clock) {
                    log::warn!("Conflict detected for {}/{}", op.table, op.record_id);
                    self.resolve_conflict(op, &local_clock).await?;
                    continue;
                }
            }
            
            // åº”ç”¨æ“ä½œ
            match op.op_type {
                OperationType::Insert | OperationType::Update => {
                    // ä½¿ç”¨ UPSERT è¯­æ³•
                    let sql = format!(
                        "INSERT OR REPLACE INTO {} VALUES (...)",
                        op.table
                    );
                    // æ‰§è¡Œ SQL (éœ€è¦æ ¹æ®å®é™…è¡¨ç»“æ„å®ç°)
                }
                OperationType::Delete => {
                    let sql = format!("DELETE FROM {} WHERE id = ?", op.table);
                    // æ‰§è¡Œ SQL
                }
            }
            
            // æ›´æ–°å‘é‡æ—¶é’Ÿ
            self.vector_clock.merge(&op.vector_clock);
        }
        
        tx.commit()?;
        
        // æ›´æ–°æœ¬åœ°ç‰ˆæœ¬å·
        self.local_version = self.local_version.max(delta.version);
        
        Ok(())
    }
    
    /// å†²çªè§£å†³ç­–ç•¥ï¼šLast Write Wins (LWW)
    async fn resolve_conflict(
        &self,
        op: &Operation,
        local_clock: &VectorClock,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // æ¯”è¾ƒå‘é‡æ—¶é’Ÿçš„æ€»å’Œï¼ˆæ›´å¤§çš„èƒœå‡ºï¼‰
        let remote_sum: i64 = op.vector_clock.clocks.values().sum();
        let local_sum: i64 = local_clock.clocks.values().sum();
        
        if remote_sum > local_sum {
            log::info!("Remote wins for {}/{}", op.table, op.record_id);
            // åº”ç”¨è¿œç¨‹å˜æ›´
        } else {
            log::info!("Local wins for {}/{}", op.table, op.record_id);
            // ä¿ç•™æœ¬åœ°å˜æ›´
        }
        
        Ok(())
    }
    
    /// è®¡ç®—æ“ä½œåˆ—è¡¨çš„ SHA256 æ ¡éªŒå’Œ
    fn calculate_checksum(&self, operations: &[Operation]) -> String {
        use sha2::{Sha256, Digest};
        let data = serde_json::to_string(operations).unwrap();
        let hash = Sha256::digest(data.as_bytes());
        format!("{:x}", hash)
    }
    
    // è¾…åŠ©æ–¹æ³•ï¼ˆéœ€è¦æ ¹æ®å®é™…æ•°æ®åº“å®ç°ï¼‰
    async fn get_local_changes(&self) -> Result<Vec<Operation>, Box<dyn std::error::Error>> {
        // ä» sync_metadata è¡¨è·å–æœªåŒæ­¥çš„å˜æ›´
        todo!("å®ç°ä»æœ¬åœ°æ•°æ®åº“è¯»å–æœªåŒæ­¥å˜æ›´")
    }
    
    async fn mark_synced(&self, operations: &[Operation]) -> Result<(), Box<dyn std::error::Error>> {
        // æ ‡è®°è¿™äº›æ“ä½œå·²åŒæ­¥
        todo!("å®ç°æ ‡è®°å·²åŒæ­¥")
    }
    
    async fn download_index(&self) -> Result<Vec<DeltaMeta>, Box<dyn std::error::Error>> {
        let data = self.s3_client.download("deltas/index.json").await?;
        Ok(serde_json::from_slice(&data)?)
    }
    
    async fn update_index(&self, delta: &Delta) -> Result<(), Box<dyn std::error::Error>> {
        // ä¸‹è½½ç°æœ‰ç´¢å¼•ï¼Œè¿½åŠ æ–° deltaï¼Œé‡æ–°ä¸Šä¼ 
        todo!("å®ç°ç´¢å¼•æ›´æ–°")
    }
    
    fn get_connection(&self) -> rusqlite::Connection {
        todo!("è·å–æ•°æ®åº“è¿æ¥")
    }
    
    async fn get_local_vector_clock(
        &self,
        table: &str,
        record_id: &str,
    ) -> Result<Option<VectorClock>, Box<dyn std::error::Error>> {
        todo!("è·å–æœ¬åœ°è®°å½•çš„å‘é‡æ—¶é’Ÿ")
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct DeltaMeta {
    version: i64,
    device_id: String,
    date: String,
}
```

### 3.4 å¿«ç…§ç®¡ç†

```rust
// src-tauri/src/sync/snapshot.rs

use serde::{Deserialize, Serialize};
use flate2::write::GzEncoder;
use flate2::read::GzDecoder;
use flate2::Compression;
use std::io::{Write, Read};

#[derive(Debug, Serialize, Deserialize)]
pub struct Snapshot {
    pub version: i64,
    pub timestamp: String,
    pub tables: Vec<TableSnapshot>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TableSnapshot {
    pub name: String,
    pub records: Vec<serde_json::Value>,
}

pub struct SnapshotManager {
    s3_client: crate::sync::s3_client::S3SyncClient,
}

impl SnapshotManager {
    pub fn new(s3_client: crate::sync::s3_client::S3SyncClient) -> Self {
        Self { s3_client }
    }
    
    /// åˆ›å»ºå¹¶ä¸Šä¼ å¿«ç…§
    pub async fn create_snapshot(&self, version: i64) -> Result<(), Box<dyn std::error::Error>> {
        // 1. å¯¼å‡ºæ‰€æœ‰è¡¨
        let snapshot = self.export_all_tables().await?;
        
        // 2. å‹ç¼©ï¼ˆä½¿ç”¨ gzipï¼‰
        let compressed = self.compress(&snapshot)?;
        
        // 3. ä¸Šä¼ åˆ° S3
        let key = format!("snapshots/snapshot-v{}.json.gz", version);
        self.s3_client.upload(&key, compressed).await?;
        
        // 4. æ›´æ–°æœ€æ–°å¿«ç…§æŒ‡é’ˆ
        self.update_latest_pointer(version).await?;
        
        log::info!("Created snapshot version {}", version);
        Ok(())
    }
    
    /// ä» S3 æ¢å¤å¿«ç…§
    pub async fn restore_snapshot(&self, version: Option<i64>) -> Result<(), Box<dyn std::error::Error>> {
        // 1. ç¡®å®šå¿«ç…§ç‰ˆæœ¬ï¼ˆæœªæŒ‡å®šåˆ™ä½¿ç”¨æœ€æ–°ï¼‰
        let version = match version {
            Some(v) => v,
            None => self.get_latest_version().await?,
        };
        
        // 2. ä¸‹è½½å¿«ç…§
        let key = format!("snapshots/snapshot-v{}.json.gz", version);
        let compressed = self.s3_client.download(&key).await?;
        
        // 3. è§£å‹
        let snapshot: Snapshot = self.decompress(&compressed)?;
        
        // 4. æ¸…ç©ºæœ¬åœ°æ•°æ®åº“
        self.truncate_all_tables().await?;
        
        // 5. å¯¼å…¥æ•°æ®
        for table in &snapshot.tables {
            self.import_table(table).await?;
        }
        
        log::info!("Restored snapshot version {}", version);
        Ok(())
    }
    
    /// æ¸…ç†æ—§å¿«ç…§ï¼ˆä¿ç•™æœ€è¿‘ N ä¸ªï¼‰
    pub async fn cleanup_old_snapshots(&self, keep_count: usize) -> Result<(), Box<dyn std::error::Error>> {
        let snapshots = self.s3_client.list("snapshots/").await?;
        
        // æå–ç‰ˆæœ¬å·å¹¶æ’åº
        let mut versions: Vec<i64> = snapshots
            .iter()
            .filter_map(|key| {
                key.strip_prefix("snapshots/snapshot-v")
                    .and_then(|s| s.strip_suffix(".json.gz"))
                    .and_then(|s| s.parse().ok())
            })
            .collect();
        
        versions.sort_unstable();
        versions.reverse(); // é™åº
        
        // åˆ é™¤æ—§å¿«ç…§
        for version in versions.iter().skip(keep_count) {
            let key = format!("snapshots/snapshot-v{}.json.gz", version);
            self.s3_client.delete(&key).await?;
            log::info!("Deleted old snapshot version {}", version);
        }
        
        Ok(())
    }
    
    /// å‹ç¼©å¿«ç…§æ•°æ®
    fn compress(&self, snapshot: &Snapshot) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
        let json = serde_json::to_vec(snapshot)?;
        let mut encoder = GzEncoder::new(Vec::new(), Compression::best());
        encoder.write_all(&json)?;
        Ok(encoder.finish()?)
    }
    
    /// è§£å‹å¿«ç…§æ•°æ®
    fn decompress(&self, data: &[u8]) -> Result<Snapshot, Box<dyn std::error::Error>> {
        let mut decoder = GzDecoder::new(data);
        let mut json = Vec::new();
        decoder.read_to_end(&mut json)?;
        Ok(serde_json::from_slice(&json)?)
    }
    
    async fn export_all_tables(&self) -> Result<Snapshot, Box<dyn std::error::Error>> {
        todo!("å®ç°æ•°æ®åº“å¯¼å‡º")
    }
    
    async fn get_latest_version(&self) -> Result<i64, Box<dyn std::error::Error>> {
        let data = self.s3_client.download("snapshots/latest.json").await?;
        let meta: serde_json::Value = serde_json::from_slice(&data)?;
        Ok(meta["version"].as_i64().unwrap())
    }
    
    async fn update_latest_pointer(&self, version: i64) -> Result<(), Box<dyn std::error::Error>> {
        let meta = serde_json::json!({
            "version": version,
            "updated_at": chrono::Utc::now().to_rfc3339(),
        });
        self.s3_client.upload("snapshots/latest.json", serde_json::to_vec(&meta)?).await?;
        Ok(())
    }
    
    async fn truncate_all_tables(&self) -> Result<(), Box<dyn std::error::Error>> {
        todo!("å®ç°æ¸…ç©ºæ‰€æœ‰è¡¨")
    }
    
    async fn import_table(&self, table: &TableSnapshot) -> Result<(), Box<dyn std::error::Error>> {
        todo!("å®ç°è¡¨æ•°æ®å¯¼å…¥")
    }
}
```

### 3.5 Tauri å‘½ä»¤

```rust
// src-tauri/src/commands/sync.rs

use tauri::State;
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct SyncState {
    pub engine: Arc<Mutex<Option<crate::sync::delta_sync::DeltaSyncEngine>>>,
}

#[tauri::command]
pub async fn sync_init(
    bucket: String,
    device_id: String,
    endpoint: Option<String>,
    access_key: Option<String>,
    secret_key: Option<String>,
    state: State<'_, SyncState>,
) -> Result<String, String> {
    use crate::sync::s3_client::S3SyncClient;
    use crate::sync::delta_sync::DeltaSyncEngine;
    
    let client = if let (Some(ep), Some(ak), Some(sk)) = (endpoint, access_key, secret_key) {
        S3SyncClient::new_with_endpoint(bucket, device_id.clone(), ep, ak, sk)
            .await
            .map_err(|e| e.to_string())?
    } else {
        S3SyncClient::new(bucket, device_id.clone())
            .await
            .map_err(|e| e.to_string())?
    };
    
    let engine = DeltaSyncEngine::new(client, device_id);
    
    let mut guard = state.engine.lock().await;
    *guard = Some(engine);
    
    Ok("Sync initialized".to_string())
}

#[tauri::command]
pub async fn sync_push(state: State<'_, SyncState>) -> Result<String, String> {
    let mut guard = state.engine.lock().await;
    
    if let Some(engine) = guard.as_mut() {
        engine.push().await.map_err(|e| e.to_string())?;
        Ok("Push completed".to_string())
    } else {
        Err("Sync not initialized".to_string())
    }
}

#[tauri::command]
pub async fn sync_pull(state: State<'_, SyncState>) -> Result<usize, String> {
    let mut guard = state.engine.lock().await;
    
    if let Some(engine) = guard.as_mut() {
        let deltas = engine.pull().await.map_err(|e| e.to_string())?;
        Ok(deltas.len())
    } else {
        Err("Sync not initialized".to_string())
    }
}

#[tauri::command]
pub async fn sync_full(state: State<'_, SyncState>) -> Result<String, String> {
    // å…ˆæ‹‰å–ï¼Œåæ¨é€ï¼ˆé¿å…è¦†ç›–ï¼‰
    let pulled = sync_pull(state.clone()).await?;
    sync_push(state).await?;
    Ok(format!("Synced: {} changes pulled", pulled))
}

#[tauri::command]
pub async fn snapshot_create(
    version: i64,
    state: State<'_, SyncState>,
) -> Result<String, String> {
    // åˆ›å»ºå¿«ç…§
    todo!("å®ç°å¿«ç…§åˆ›å»ºå‘½ä»¤")
}

#[tauri::command]
pub async fn snapshot_restore(
    version: Option<i64>,
    state: State<'_, SyncState>,
) -> Result<String, String> {
    // æ¢å¤å¿«ç…§
    todo!("å®ç°å¿«ç…§æ¢å¤å‘½ä»¤")
}
```

### 3.6 åŒæ­¥ä¸è¯„è®ºçš„è‡ªåŠ¨é›†æˆ

é¡¹ç›®è¯„è®ºï¼ˆ`project_comments`ï¼‰é€šè¿‡ `0004_add_project_comments.sql` ä¸­å®šä¹‰çš„ INSERT/UPDATE/DELETE è§¦å‘å™¨è‡ªåŠ¨çº³å…¥åŒæ­¥æµç¨‹ã€‚è¯„è®ºçš„ CRUD æ“ä½œï¼ˆ`cmd_comment_create`/`cmd_comment_update`/`cmd_comment_delete`ï¼‰æ— éœ€é¢å¤–åŒæ­¥ä»£ç â€”â€”è§¦å‘å™¨ä¼šè‡ªåŠ¨å°†å˜æ›´å†™å…¥ `sync_metadata` è¡¨ï¼Œç”± Delta Sync Engine ç»Ÿä¸€å¤„ç†ã€‚

### 3.7 æ³¨å†Œåˆ° Tauri

```rust
// src-tauri/src/lib.rs

mod sync;

use sync::SyncState;
use std::sync::Arc;
use tokio::sync::Mutex;

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    tauri::Builder::default()
        .manage(SyncState {
            engine: Arc::new(Mutex::new(None)),
        })
        .invoke_handler(tauri::generate_handler![
            // ... ç°æœ‰å‘½ä»¤ ...
            commands::sync::sync_init,
            commands::sync::sync_push,
            commands::sync::sync_pull,
            commands::sync::sync_full,
            commands::sync::snapshot_create,
            commands::sync::snapshot_restore,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
```

---

## 4. å‰ç«¯å®ç°

### 4.1 S3 åŒæ­¥ç®¡ç†å™¨

```typescript
// src/sync/s3-sync-manager.ts

import { invoke } from '@tauri-apps/api/core';

export interface SyncConfig {
  bucket: string;
  deviceId: string;
  endpoint?: string;
  accessKey?: string;
  secretKey?: string;
}

export interface SyncStatus {
  status: 'idle' | 'syncing' | 'error';
  lastSync: Date | null;
  error: string | null;
}

export class S3SyncManager {
  private syncInterval: number | null = null;
  private status: SyncStatus = {
    status: 'idle',
    lastSync: null,
    error: null,
  };
  private listeners: Array<(status: SyncStatus) => void> = [];
  
  constructor(private config: SyncConfig) {}
  
  /**
   * åˆå§‹åŒ–åŒæ­¥å¼•æ“
   */
  async initialize(): Promise<void> {
    try {
      await invoke('sync_init', this.config);
      console.log('S3 sync initialized');
    } catch (error) {
      console.error('Failed to initialize sync:', error);
      throw error;
    }
  }
  
  /**
   * æ‰§è¡Œå®Œæ•´åŒæ­¥ï¼ˆæ‹‰å– + æ¨é€ï¼‰
   */
  async sync(): Promise<void> {
    if (this.status.status === 'syncing') {
      console.log('Sync already in progress');
      return;
    }
    
    this.updateStatus({ status: 'syncing', error: null });
    
    try {
      const result = await invoke<string>('sync_full');
      console.log('Sync completed:', result);
      
      this.updateStatus({
        status: 'idle',
        lastSync: new Date(),
        error: null,
      });
    } catch (error: any) {
      console.error('Sync failed:', error);
      
      this.updateStatus({
        status: 'error',
        error: error.message || 'Unknown error',
      });
      
      throw error;
    }
  }
  
  /**
   * ä»…æ¨é€æœ¬åœ°å˜æ›´
   */
  async push(): Promise<void> {
    await invoke('sync_push');
  }
  
  /**
   * ä»…æ‹‰å–è¿œç¨‹å˜æ›´
   */
  async pull(): Promise<number> {
    return await invoke<number>('sync_pull');
  }
  
  /**
   * åˆ›å»ºå¿«ç…§
   */
  async createSnapshot(version: number): Promise<void> {
    await invoke('snapshot_create', { version });
  }
  
  /**
   * æ¢å¤å¿«ç…§
   */
  async restoreSnapshot(version?: number): Promise<void> {
    await invoke('snapshot_restore', { version });
  }
  
  /**
   * å¯åŠ¨è‡ªåŠ¨åŒæ­¥
   */
  startAutoSync(intervalMs: number = 60000): void {
    if (this.syncInterval !== null) {
      console.warn('Auto sync already started');
      return;
    }
    
    this.syncInterval = window.setInterval(() => {
      this.sync().catch(console.error);
    }, intervalMs);
    
    // ç«‹å³æ‰§è¡Œä¸€æ¬¡
    this.sync().catch(console.error);
    
    console.log(`Auto sync started (interval: ${intervalMs}ms)`);
  }
  
  /**
   * åœæ­¢è‡ªåŠ¨åŒæ­¥
   */
  stopAutoSync(): void {
    if (this.syncInterval !== null) {
      clearInterval(this.syncInterval);
      this.syncInterval = null;
      console.log('Auto sync stopped');
    }
  }
  
  /**
   * è·å–åŒæ­¥çŠ¶æ€
   */
  getStatus(): SyncStatus {
    return { ...this.status };
  }
  
  /**
   * ç›‘å¬çŠ¶æ€å˜åŒ–
   */
  onStatusChange(callback: (status: SyncStatus) => void): () => void {
    this.listeners.push(callback);
    
    // è¿”å›å–æ¶ˆç›‘å¬å‡½æ•°
    return () => {
      const index = this.listeners.indexOf(callback);
      if (index > -1) {
        this.listeners.splice(index, 1);
      }
    };
  }
  
  private updateStatus(partial: Partial<SyncStatus>): void {
    this.status = { ...this.status, ...partial };
    this.listeners.forEach(callback => callback(this.status));
  }
}
```

### 4.2 åŒæ­¥çŠ¶æ€ UI ç»„ä»¶

```typescript
// src/components/SyncStatusBar.tsx

import { Badge, Button, Group, Loader, Text, Tooltip } from '@mantine/core';
import { IconCloud, IconCloudOff, IconRefresh } from '@tabler/icons-react';
import { useEffect, useState } from 'react';
import { formatDistanceToNow } from 'date-fns';
import { zhCN } from 'date-fns/locale';
import type { SyncStatus } from '../sync/s3-sync-manager';

interface SyncStatusBarProps {
  syncManager: any; // S3SyncManager
}

export function SyncStatusBar({ syncManager }: SyncStatusBarProps) {
  const [status, setStatus] = useState<SyncStatus>(syncManager.getStatus());
  const [syncing, setSyncing] = useState(false);
  
  useEffect(() => {
    // ç›‘å¬çŠ¶æ€å˜åŒ–
    const unsubscribe = syncManager.onStatusChange(setStatus);
    return unsubscribe;
  }, [syncManager]);
  
  const handleManualSync = async () => {
    setSyncing(true);
    try {
      await syncManager.sync();
    } finally {
      setSyncing(false);
    }
  };
  
  const getStatusColor = () => {
    switch (status.status) {
      case 'syncing': return 'blue';
      case 'error': return 'red';
      case 'idle': return status.lastSync ? 'green' : 'gray';
    }
  };
  
  const getStatusText = () => {
    if (status.status === 'syncing') return 'åŒæ­¥ä¸­...';
    if (status.status === 'error') return `é”™è¯¯: ${status.error}`;
    if (status.lastSync) {
      return `ä¸Šæ¬¡åŒæ­¥: ${formatDistanceToNow(status.lastSync, { locale: zhCN, addSuffix: true })}`;
    }
    return 'æœªåŒæ­¥';
  };
  
  return (
    <Group gap="xs" style={{ padding: '8px 16px', borderTop: '1px solid var(--mantine-color-gray-2)' }}>
      <Badge
        leftSection={
          status.status === 'syncing' ? (
            <Loader size="xs" />
          ) : status.status === 'error' ? (
            <IconCloudOff size={12} />
          ) : (
            <IconCloud size={12} />
          )
        }
        color={getStatusColor()}
        variant="light"
      >
        äº‘åŒæ­¥
      </Badge>
      
      <Text size="xs" c="dimmed">
        {getStatusText()}
      </Text>
      
      <Tooltip label="ç«‹å³åŒæ­¥">
        <Button
          variant="subtle"
          size="xs"
          onClick={handleManualSync}
          loading={syncing || status.status === 'syncing'}
          leftSection={<IconRefresh size={14} />}
        >
          åŒæ­¥
        </Button>
      </Tooltip>
    </Group>
  );
}
```

### 4.3 è®¾ç½®é¡µé¢é›†æˆ

```typescript
// src/pages/Settings.tsx (æ–°å¢åŒæ­¥é…ç½®)

import { Switch, TextInput, PasswordInput } from '@mantine/core';
import { S3SyncManager } from '../sync/s3-sync-manager';

export function Settings() {
  const [syncConfig, setSyncConfig] = useState({
    enabled: false,
    bucket: '',
    endpoint: '',
    accessKey: '',
    secretKey: '',
  });
  
  const handleSaveSync = async () => {
    try {
      // ä¿å­˜åˆ°æœ¬åœ°é…ç½®
      await invoke('save_sync_config', { config: syncConfig });
      
      // åˆå§‹åŒ–åŒæ­¥
      const manager = new S3SyncManager({
        bucket: syncConfig.bucket,
        deviceId: await getDeviceId(),
        endpoint: syncConfig.endpoint,
        accessKey: syncConfig.accessKey,
        secretKey: syncConfig.secretKey,
      });
      
      await manager.initialize();
      
      // å¯åŠ¨è‡ªåŠ¨åŒæ­¥
      if (syncConfig.enabled) {
        manager.startAutoSync();
      }
      
      showSuccess('åŒæ­¥é…ç½®å·²ä¿å­˜');
    } catch (error: any) {
      showError(error.message);
    }
  };
  
  return (
    <Stack gap="md">
      <Paper>
        <Stack gap="md">
          <Title order={4}>äº‘åŒæ­¥è®¾ç½®</Title>
          
          <Switch
            label="å¯ç”¨äº‘åŒæ­¥"
            checked={syncConfig.enabled}
            onChange={(e) => setSyncConfig({ ...syncConfig, enabled: e.currentTarget.checked })}
          />
          
          <TextInput
            label="S3 Bucket"
            placeholder="my-project-sync"
            value={syncConfig.bucket}
            onChange={(e) => setSyncConfig({ ...syncConfig, bucket: e.currentTarget.value })}
          />
          
          <TextInput
            label="Endpoint (å¯é€‰)"
            placeholder="https://abc123.r2.cloudflarestorage.com"
            description="ç•™ç©ºä½¿ç”¨ AWS S3ï¼Œæˆ–å¡«å†™ Cloudflare R2/MinIO ç­‰ç«¯ç‚¹"
            value={syncConfig.endpoint}
            onChange={(e) => setSyncConfig({ ...syncConfig, endpoint: e.currentTarget.value })}
          />
          
          <TextInput
            label="Access Key"
            placeholder="AKIAIOSFODNN7EXAMPLE"
            value={syncConfig.accessKey}
            onChange={(e) => setSyncConfig({ ...syncConfig, accessKey: e.currentTarget.value })}
          />
          
          <PasswordInput
            label="Secret Key"
            placeholder="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
            value={syncConfig.secretKey}
            onChange={(e) => setSyncConfig({ ...syncConfig, secretKey: e.currentTarget.value })}
          />
          
          <Group>
            <Button onClick={handleSaveSync}>ä¿å­˜é…ç½®</Button>
            <Button variant="light" onClick={() => testConnection()}>æµ‹è¯•è¿æ¥</Button>
          </Group>
        </Stack>
      </Paper>
    </Stack>
  );
}
```

---

## 5. æˆæœ¬åˆ†æ

### 5.1 Cloudflare R2ï¼ˆæ¨è â­ï¼‰

```
å­˜å‚¨: 10 GB å…è´¹ï¼Œä¹‹å $0.015/GB/æœˆ
è¯»å–: å…è´¹ï¼ˆæ— é™ï¼‰âœ…
å†™å…¥: å…è´¹ï¼ˆæ¯æœˆ100ä¸‡æ¬¡ï¼‰âœ…
å‡ºç«™æµé‡: å…è´¹ âœ…

æœˆè´¹ç”¨ä¼°ç®—ï¼ˆä¸ªäººä½¿ç”¨ï¼‰:
- æ•°æ®åº“å¿«ç…§ (50MB) Ã— 4å‘¨ = 200 MB
- å¢é‡æ—¥å¿— (1MB/å¤©) Ã— 30å¤© = 30 MB
- æ€»è®¡: ~250 MB â†’ å…è´¹é¢åº¦å†…

å¹´è´¹ç”¨: $0 ğŸ‰
```

### 5.2 AWS S3

```
å­˜å‚¨: $0.023/GB/æœˆ
è¯»å–: $0.0004/1000æ¬¡
å†™å…¥: $0.005/1000æ¬¡
å‡ºç«™æµé‡: $0.09/GBï¼ˆå‰ 100GB/æœˆï¼‰

æœˆè´¹ç”¨ä¼°ç®—:
- å­˜å‚¨: 0.25 GB Ã— $0.023 = $0.006
- å†™å…¥: 100æ¬¡/å¤© Ã— 30 Ã— $0.005/1000 = $0.015
- è¯»å–: 100æ¬¡/å¤© Ã— 30 Ã— $0.0004/1000 = $0.001
- æµé‡: 0.01 GB Ã— $0.09 = $0.001
æ€»è®¡: ~$0.02/æœˆ

å¹´è´¹ç”¨: ~$0.25
```

### 5.3 MinIOï¼ˆè‡ªæ‰˜ç®¡ï¼‰

```
æœåŠ¡å™¨: DigitalOcean Droplet $6/æœˆ
å­˜å‚¨: åŒ…å« 50GB SSD
å¸¦å®½: 2TB/æœˆ

æœˆè´¹ç”¨: $6
å¹´è´¹ç”¨: $72

ä¼˜ç‚¹: å®Œå…¨å¯æ§ï¼Œæ•°æ®ç§æœ‰
ç¼ºç‚¹: éœ€è¦ç»´æŠ¤
```

**ç»“è®ºï¼šæ¨è Cloudflare R2ï¼ˆé›¶æˆæœ¬ï¼‰**

---

## 6. å®‰å…¨æ€§

### 6.1 å®¢æˆ·ç«¯åŠ å¯†ï¼ˆç«¯åˆ°ç«¯ï¼‰

```rust
// src-tauri/src/sync/encryption.rs

use aes_gcm::{Aes256Gcm, Key, Nonce};
use aes_gcm::aead::{Aead, NewAead};
use argon2::{self, Config};

pub struct E2EEncryption {
    cipher: Aes256Gcm,
}

impl E2EEncryption {
    /// ä»ç”¨æˆ·å¯†ç æ´¾ç”ŸåŠ å¯†å¯†é’¥
    pub fn from_password(password: &str, salt: &[u8]) -> Self {
        let config = Config::default();
        let key_bytes = argon2::hash_raw(password.as_bytes(), salt, &config)
            .expect("Key derivation failed");
        
        let key = Key::from_slice(&key_bytes[0..32]);
        let cipher = Aes256Gcm::new(key);
        
        Self { cipher }
    }
    
    /// åŠ å¯†æ•°æ®
    pub fn encrypt(&self, plaintext: &[u8]) -> Result<Vec<u8>, String> {
        let nonce = Self::generate_nonce();
        let ciphertext = self.cipher
            .encrypt(Nonce::from_slice(&nonce), plaintext)
            .map_err(|e| e.to_string())?;
        
        // æ ¼å¼: [nonce (12 bytes)][ciphertext]
        let mut result = nonce.to_vec();
        result.extend_from_slice(&ciphertext);
        Ok(result)
    }
    
    /// è§£å¯†æ•°æ®
    pub fn decrypt(&self, encrypted: &[u8]) -> Result<Vec<u8>, String> {
        if encrypted.len() < 12 {
            return Err("Invalid encrypted data".to_string());
        }
        
        let (nonce, ciphertext) = encrypted.split_at(12);
        
        self.cipher
            .decrypt(Nonce::from_slice(nonce), ciphertext)
            .map_err(|e| e.to_string())
    }
    
    fn generate_nonce() -> [u8; 12] {
        use rand::RngCore;
        let mut nonce = [0u8; 12];
        rand::thread_rng().fill_bytes(&mut nonce);
        nonce
    }
}
```

### 6.2 S3 Bucket ç­–ç•¥ï¼ˆIAM æƒé™ï¼‰

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowUserAccess",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::ACCOUNT_ID:user/project-sync-user"
      },
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-project-sync/*",
        "arn:aws:s3:::my-project-sync"
      ]
    }
  ]
}
```

---

## 7. éƒ¨ç½²æ­¥éª¤

### 7.1 Cloudflare R2 è®¾ç½®

```bash
# 1. åˆ›å»º R2 Bucket
# è®¿é—® Cloudflare Dashboard â†’ R2 â†’ Create Bucket
# Bucket åç§°: project-management-sync

# 2. åˆ›å»º API Token
# R2 â†’ Manage R2 API Tokens â†’ Create API Token
# æƒé™: Object Read & Write
# ä¿å­˜: Access Key ID å’Œ Secret Access Key

# 3. è·å– Endpoint URL
# æ ¼å¼: https://<account-id>.r2.cloudflarestorage.com
```

### 7.2 åº”ç”¨é…ç½®

```toml
# src-tauri/sync-config.toml

[s3]
provider = "cloudflare-r2"
bucket = "project-management-sync"
endpoint = "https://abc123.r2.cloudflarestorage.com"

[sync]
auto_sync_interval_seconds = 60
snapshot_interval_hours = 24
keep_snapshots_count = 7

[encryption]
enabled = true
# å¯†ç ç”±ç”¨æˆ·åœ¨é¦–æ¬¡å¯åŠ¨æ—¶è®¾ç½®
```

### 7.3 ç¯å¢ƒå˜é‡

```bash
# .env (å¼€å‘ç¯å¢ƒ)
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=auto  # R2 ä½¿ç”¨ "auto"
```

---

## 8. æµ‹è¯•

### 8.1 å•å…ƒæµ‹è¯•

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_s3_upload_download() {
        let client = S3SyncClient::new(...).await.unwrap();
        
        let data = b"test data";
        client.upload("test.txt", data.to_vec()).await.unwrap();
        
        let downloaded = client.download("test.txt").await.unwrap();
        assert_eq!(data, downloaded.as_slice());
        
        client.delete("test.txt").await.unwrap();
    }
    
    #[test]
    fn test_vector_clock_merge() {
        let mut clock1 = VectorClock::new("device-1".to_string());
        let mut clock2 = VectorClock::new("device-2".to_string());
        
        clock1.increment("device-1");
        clock2.increment("device-2");
        
        clock1.merge(&clock2);
        
        assert_eq!(clock1.clocks.get("device-1"), Some(&1));
        assert_eq!(clock1.clocks.get("device-2"), Some(&1));
    }
}
```

### 8.2 é›†æˆæµ‹è¯•

```typescript
// tests/sync.test.ts

describe('S3 Sync', () => {
  test('should sync between two devices', async () => {
    // è®¾å¤‡ A åˆ›å»ºé¡¹ç›®
    const projectA = await createProject({ name: 'Test Project' });
    
    // è®¾å¤‡ A æ¨é€
    await syncManagerA.push();
    
    // è®¾å¤‡ B æ‹‰å–
    await syncManagerB.pull();
    
    // éªŒè¯è®¾å¤‡ B æœ‰è¯¥é¡¹ç›®
    const projectB = await getProject(projectA.id);
    expect(projectB.name).toBe('Test Project');
  });
  
  test('should resolve conflicts with LWW', async () => {
    // ä¸¤ä¸ªè®¾å¤‡åŒæ—¶ä¿®æ”¹
    await updateProject(projectId, { name: 'Name A' }); // è®¾å¤‡ A
    await updateProject(projectId, { name: 'Name B' }); // è®¾å¤‡ B
    
    // åŒæ­¥
    await syncManagerA.sync();
    await syncManagerB.sync();
    
    // éªŒè¯æœ€ç»ˆä¸€è‡´
    const finalProject = await getProject(projectId);
    expect(['Name A', 'Name B']).toContain(finalProject.name);
  });
});
```

---

## 9. å®æ–½è®¡åˆ’

### æ—¶é—´çº¿ï¼ˆ3-4å‘¨ï¼‰

```
Week 1: åŸºç¡€è®¾æ–½
  - Day 1-2: æ·»åŠ ä¾èµ–ï¼ŒS3 å®¢æˆ·ç«¯å°è£…
  - Day 3-4: Delta æ•°æ®ç»“æ„è®¾è®¡
  - Day 5: å•å…ƒæµ‹è¯•

Week 2: åŒæ­¥å¼•æ“
  - Day 1-2: æ¨é€é€»è¾‘å®ç°
  - Day 3-4: æ‹‰å–é€»è¾‘å®ç°
  - Day 5: å‘é‡æ—¶é’Ÿå’Œå†²çªè§£å†³

Week 3: å¿«ç…§ + å‰ç«¯
  - Day 1-2: å¿«ç…§ç®¡ç†å™¨
  - Day 3-4: å‰ç«¯åŒæ­¥ç®¡ç†å™¨
  - Day 5: UI ç»„ä»¶é›†æˆ

Week 4: æµ‹è¯• + ä¼˜åŒ–
  - Day 1-2: é›†æˆæµ‹è¯•
  - Day 3-4: æ€§èƒ½ä¼˜åŒ–
  - Day 5: æ–‡æ¡£å®Œå–„
```

### é‡Œç¨‹ç¢‘æ£€æŸ¥ç‚¹

- âœ… **M1**: S3 ä¸Šä¼ /ä¸‹è½½åŠŸèƒ½éªŒè¯
- âœ… **M2**: å•è®¾å¤‡åŒæ­¥å·¥ä½œæ­£å¸¸
- âœ… **M3**: å¤šè®¾å¤‡åŒæ­¥æµ‹è¯•é€šè¿‡
- âœ… **M4**: å†²çªåœºæ™¯æµ‹è¯•é€šè¿‡
- âœ… **M5**: æ€§èƒ½è¾¾æ ‡ï¼Œæ–‡æ¡£é½å…¨

---

## 10. ç›‘æ§ä¸è¿ç»´

### 10.1 åŒæ­¥æŒ‡æ ‡

```typescript
export interface SyncMetrics {
  totalSyncs: number;
  successfulSyncs: number;
  failedSyncs: number;
  averageLatency: number;
  lastError: string | null;
}
```

### 10.2 æ—¥å¿—è®°å½•

```rust
// è®°å½•æ¯æ¬¡åŒæ­¥æ“ä½œ
log::info!("Sync started: device={}", device_id);
log::info!("Pushed {} deltas", delta_count);
log::info!("Pulled {} deltas", delta_count);
log::error!("Sync failed: {}", error);
```

---

## 11. æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

- âœ… **é›¶æˆæœ¬**ï¼šä½¿ç”¨ Cloudflare R2 å®Œå…¨å…è´¹
- âœ… **é«˜å¯é **ï¼š99.999999999% æ•°æ®æŒä¹…æ€§
- âœ… **æ˜“ç»´æŠ¤**ï¼šæ— éœ€æœåŠ¡å™¨ï¼Œè‡ªåŠ¨æ‰©å±•
- âœ… **å®‰å…¨**ï¼šæ”¯æŒç«¯åˆ°ç«¯åŠ å¯†
- âœ… **çµæ´»**ï¼šæ”¯æŒæ‰€æœ‰ S3 å…¼å®¹æœåŠ¡

### é€‚ç”¨åœºæ™¯

- âœ… ä¸ªäººæˆ–å°å›¢é˜Ÿï¼ˆ< 10äººï¼‰
- âœ… é¢„ç®—æœ‰é™
- âœ… ä¸éœ€è¦å®æ—¶ååŒï¼ˆåˆ†é’Ÿçº§å»¶è¿Ÿå¯æ¥å—ï¼‰
- âœ… ä¸æƒ³ç»´æŠ¤æœåŠ¡å™¨

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **é…ç½® R2**ï¼ˆ10åˆ†é’Ÿï¼‰
2. **æ·»åŠ ä¾èµ–**ï¼ˆ5åˆ†é’Ÿï¼‰
3. **å¤åˆ¶æ ¸å¿ƒä»£ç **ï¼ˆ1å°æ—¶ï¼‰
4. **æµ‹è¯•éªŒè¯**ï¼ˆ2å°æ—¶ï¼‰
5. **é›†æˆåˆ°åº”ç”¨**ï¼ˆ1å¤©ï¼‰

**é¢„è®¡æ€»å·¥ä½œé‡ï¼š3-4å‘¨**

---

## å‚è€ƒèµ„æ–™

- [AWS SDK for Rust](https://github.com/awslabs/aws-sdk-rust)
- [Cloudflare R2 æ–‡æ¡£](https://developers.cloudflare.com/r2/)
- [Vector Clock è®ºæ–‡](https://en.wikipedia.org/wiki/Vector_clock)
- [CRDT ç®€ä»‹](https://crdt.tech/)
